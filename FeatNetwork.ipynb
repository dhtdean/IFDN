{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.layers import Layer, Input, GlobalAveragePooling2D, Lambda, Dense\n",
    "from keras.layers import ConvLSTM2D, Conv2D, AveragePooling2D, BatchNormalization\n",
    "from keras.constraints import unit_norm, non_neg\n",
    "from keras.activations import softmax\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.constraints import Constraint\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import _Conv\n",
    "from keras.legacy import interfaces\n",
    "from keras.engine import InputSpec\n",
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DSymPadding( _Conv ) :\n",
    "    @interfaces.legacy_conv2d_support\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 padding='same',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Conv2DSymPadding, self).__init__(\n",
    "            rank=2,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "    def get_config(self):\n",
    "        config = super(Conv2DSymPadding, self).get_config()\n",
    "        config.pop('rank')\n",
    "        return config\n",
    "    def call( self, inputs ) :\n",
    "        if ( isinstance( self.kernel_size, tuple ) ) :\n",
    "            kh, kw = self.kernel_size\n",
    "        else :\n",
    "            kh = kw = self.kernel_size\n",
    "        ph, pw = kh//2, kw//2\n",
    "        inputs_pad = tf.pad( inputs, [[0,0],[ph,ph],[pw,pw],[0,0]], mode='symmetric' )\n",
    "        outputs = K.conv2d(\n",
    "                inputs_pad,\n",
    "                self.kernel,\n",
    "                strides=self.strides,\n",
    "                padding='valid',\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayarConstraint( Constraint ) :\n",
    "    def __init__( self ) :\n",
    "        self.mask = None\n",
    "    def _initialize_mask( self, w ) :\n",
    "        nb_rows, nb_cols, nb_inputs, nb_outputs = K.int_shape(w)\n",
    "        m = np.zeros([nb_rows, nb_cols, nb_inputs, nb_outputs]).astype('float32')\n",
    "        m[nb_rows//2,nb_cols//2] = 1.\n",
    "        self.mask = K.variable( m, dtype='float32' )\n",
    "        return\n",
    "    def __call__( self, w ) :\n",
    "        if self.mask is None :\n",
    "            self._initialize_mask(w)\n",
    "        w *= (1-self.mask)\n",
    "        rest_sum = K.sum( w, axis=(0,1), keepdims=True)\n",
    "        w /= rest_sum + K.epsilon()\n",
    "        w -= self.mask\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ii layer\n",
    "\n",
    "class IlluminationInvariant(Layer):\n",
    "    # constructor\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(IlluminationInvariant, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable alpha for this layer.\n",
    "        self.alpha = self.add_weight(name='alpha', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(IlluminationInvariant, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, img):\n",
    "        assert isinstance(img, np.ndarray)\n",
    "        assert(img.shape[2] == 3)\n",
    "        tmp = (0.5 + K.log(img[:, :, 1] / float(255)) -\n",
    "                self.alpha * K.log(img[:, :, 2] / float(255)) -\n",
    "                (1 - self.alpha) * K.log(img[:, :, 0] / float(255)))\n",
    "        return tmp\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illumination invariant computation\n",
    "def rgb2ii(img, alpha):\n",
    "    \"\"\"Convert RGB image to illumination invariant image.\"\"\"\n",
    "    ii_image = (0.5 + np.log(img[:, :, 1] / float(255)) -\n",
    "                alpha * np.log(img[:, :, 2] / float(255)) -\n",
    "                (1 - alpha) * np.log(img[:, :, 0] / float(255)))\n",
    "    return ii_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedConv2D(Conv2DSymPadding) :\n",
    "    def __init__(self, filters,\n",
    "                 select = 'all',\n",
    "                 kernel_size=(5,5),\n",
    "                 strides=(1,1),\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1,1),\n",
    "                 activation=None,\n",
    "                 padding='same',\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        self.select = select\n",
    "        super(CombinedConv2D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=(5,5),\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=None,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=None,\n",
    "            **kwargs)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        \n",
    "    def _get_srm_list( self ) :\n",
    "        # srm kernel 1                                                                                                                                \n",
    "        srm1 = np.zeros([5,5]).astype('float32')\n",
    "        srm1[1:-1,1:-1] = np.array([[-1, 2, -1],\n",
    "                                    [2, -4, 2],\n",
    "                                    [-1, 2, -1]] )\n",
    "        srm1 /= 4.\n",
    "        # srm kernel 2                                                                                                                                \n",
    "        srm2 = np.array([[-1, 2, -2, 2, -1],\n",
    "                         [2, -6, 8, -6, 2],\n",
    "                         [-2, 8, -12, 8, -2],\n",
    "                         [2, -6, 8, -6, 2],\n",
    "                         [-1, 2, -2, 2, -1]]).astype('float32')\n",
    "        srm2 /= 12.\n",
    "        # srm kernel 3                                                                                                                                \n",
    "        srm3 = np.zeros([5,5]).astype('float32')\n",
    "        srm3[2,1:-1] = np.array([1,-2,1])\n",
    "        srm3 /= 2.\n",
    "        return [ srm1, srm2, srm3 ]\n",
    "    \n",
    "    def _build_SRM_kernel( self ) :\n",
    "        kernel = []\n",
    "        srm_list = self._get_srm_list()\n",
    "        for idx, srm in enumerate( srm_list ):\n",
    "            for ch in range(3) :\n",
    "                this_ch_kernel = np.zeros([5,5,3]).astype('float32')\n",
    "                this_ch_kernel[:,:,ch] = srm\n",
    "                kernel.append( this_ch_kernel )\n",
    "        kernel = np.stack( kernel, axis=-1 )\n",
    "        srm_kernel = K.variable( kernel, dtype='float32', name='srm' )\n",
    "        return srm_kernel\n",
    "    \n",
    "    def build( self, input_shape ) :\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise( ValueError, 'The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        \n",
    "        # 1. regular conv kernels, fully trainable                                                                                                    \n",
    "        filters = self.filters - 9 - 3\n",
    "        if filters >= 1 :\n",
    "            regular_kernel_shape = self.kernel_size + (input_dim, filters)\n",
    "            self.regular_kernel = self.add_weight(shape=regular_kernel_shape,\n",
    "                                          initializer=self.kernel_initializer,\n",
    "                                          name='regular_kernel',\n",
    "                                          regularizer=self.kernel_regularizer,\n",
    "                                          constraint=self.kernel_constraint)\n",
    "        else :\n",
    "            self.regular_kernel = None\n",
    "            \n",
    "        # 2. SRM kernels, not trainable                                                                  \n",
    "        self.srm_kernel = self._build_SRM_kernel()\n",
    "        \n",
    "        # 3. bayar kernels, trainable but under constraint                                                                                            \n",
    "        bayar_kernel_shape = self.kernel_size + (input_dim, 3)\n",
    "        self.bayar_kernel = self.add_weight(shape=bayar_kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='bayar_kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=BayarConstraint())\n",
    "        \n",
    "        # 5. II kernels, trainable parameters\n",
    "        #ii_kernel_shape = self.alpha\n",
    "        \n",
    "        # 6. collect all kernels\n",
    "        if ( self.regular_kernel is not None ) :\n",
    "            if self.select is 'all':\n",
    "                all_kernels = [ self.regular_kernel,\n",
    "                                self.srm_kernel,\n",
    "                                self.bayar_kernel]\n",
    "            elif self.select is 'reg':\n",
    "                all_kernels = [self.regular_kernel]\n",
    "            elif self.select is 'srm':\n",
    "                all_kernels = [self.srm_kernel]\n",
    "            elif self.select is 'bayar':\n",
    "                all_kernels = [self.bayar_kernel]\n",
    "            else :\n",
    "                all_kernels = [ self.srm_kernel,\n",
    "                                self.bayar_kernel]\n",
    "        self.kernel = K.concatenate( all_kernels, axis=-1 )\n",
    "        \n",
    "        # Set input spec.                                                                                                                             \n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featex_vgg16_base( type=1 ) :\n",
    "    base = 16\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    # block 3\n",
    "    bname = 'b3'\n",
    "    nb_filters = 4 * base # 96\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c3')( x )\n",
    "    # block 4\n",
    "    bname = 'b4'\n",
    "    nb_filters = 8 * base # 128\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c3')( x )\n",
    "    # block 5/bottle-neck \n",
    "    bname = 'b5'\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    print (\"INFO: use activation in the last CONV={}\".format( activation ))\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n",
    "\n",
    "class GlobalStd2D( Layer ) :\n",
    "    '''Custom Keras Layer to compute sample-wise feature deviation\n",
    "    '''\n",
    "    def __init__( self, min_std_val=1e-5, **kwargs ) :\n",
    "        self.min_std_val = min_std_val\n",
    "        super( GlobalStd2D, self ).__init__( **kwargs )\n",
    "    def build( self, input_shape ) :\n",
    "        nb_feats = input_shape[-1]\n",
    "        std_shape = ( 1,1,1, nb_feats )\n",
    "        self.min_std = self.add_weight( shape=std_shape,\n",
    "                                        initializer=Constant(self.min_std_val),\n",
    "                                        name='min_std',\n",
    "                                        constraint=non_neg() )\n",
    "        self.built = True\n",
    "        return\n",
    "    def call( self, x ) :\n",
    "        x_std = K.std( x, axis=(1,2), keepdims=True )\n",
    "        x_std = K.maximum( x_std, self.min_std_val/10. + self.min_std )\n",
    "        return x_std\n",
    "    def compute_output_shape( self, input_shape ) :\n",
    "        return (input_shape[0], 1, 1, input_shape[-1] )\n",
    "\n",
    "class NestedWindowAverageFeatExtrator( Layer ) :\n",
    "    '''Custom Keras Layer of NestedWindowAverageFeatExtrator\n",
    "    '''\n",
    "    def __init__( self,\n",
    "                  window_size_list,\n",
    "                  output_mode='5d',\n",
    "                  minus_original=False,\n",
    "                  include_global=True,\n",
    "                  **kwargs ) :\n",
    "        '''\n",
    "        INPUTS:\n",
    "            win_size_list = list of int or tuples, each elem indicate a winsize of interest\n",
    "            output_mode = '5d' or '4d', where\n",
    "                          '5d' merges all win_avgs along a new time axis\n",
    "                          '4d' merges all win_avgs along the existing feat axis\n",
    "        '''\n",
    "        self.window_size_list = window_size_list\n",
    "        assert output_mode in ['5d','4d'], \"ERROR: unkown output mode={}\".format( output_mode )\n",
    "        self.output_mode = output_mode\n",
    "        self.minus_original = minus_original\n",
    "        self.include_global = include_global\n",
    "        super(NestedWindowAverageFeatExtrator, self).__init__(**kwargs)\n",
    "        \n",
    "    def build( self, input_shape ) :\n",
    "        self.num_woi = len( self.window_size_list )\n",
    "        self.count_ii = None\n",
    "        self.lut = dict()\n",
    "        self.built = True\n",
    "        self.max_wh, self.max_ww = self._get_max_size()\n",
    "        return\n",
    "    \n",
    "    def _initialize_ii_buffer( self, x ) :\n",
    "        x_pad = K.spatial_2d_padding( x, ((self.max_wh//2+1,self.max_wh//2+1), (self.max_ww//2+1,self.max_ww//2+1)) )\n",
    "        ii_x  = K.cumsum( x_pad, axis=1 )\n",
    "        ii_x2 = K.cumsum( ii_x, axis=2 )\n",
    "        return ii_x2\n",
    "    \n",
    "    def _get_max_size( self ) :\n",
    "        mh, mw = 0, 0\n",
    "        for hw in self.window_size_list :\n",
    "            if ( isinstance( hw, int ) ) :\n",
    "                h = w = hw\n",
    "            else :\n",
    "                h, w = hw[:2]\n",
    "            mh = max( h, mh )\n",
    "            mw = max( w, mw )\n",
    "        return mh, mw\n",
    "    \n",
    "    def _compute_for_one_size( self, x, x_ii, height, width ) :\n",
    "        # 1. compute valid counts for this key\n",
    "        top   = self.max_wh//2 - height//2\n",
    "        bot   = top + height\n",
    "        left  = self.max_ww//2 - width //2\n",
    "        right = left + width\n",
    "        Ay, Ax = (top, left) #self.max_wh, self.max_ww\n",
    "        By, Bx = (top, right) # Ay, Ax + width\n",
    "        Cy, Cx = (bot, right) #By + height, Bx\n",
    "        Dy, Dx = (bot, left) #Cy, Ax\n",
    "        ii_key = (height,width)\n",
    "        top_0   = -self.max_wh//2 - height//2 - 1\n",
    "        bot_0   = top_0 + height\n",
    "        left_0  = -self.max_ww//2 - width//2 - 1\n",
    "        right_0 = left_0 + width\n",
    "        Ay0, Ax0 = (top_0, left_0) #self.max_wh, self.max_ww\n",
    "        By0, Bx0 = (top_0, right_0) # Ay, Ax + width\n",
    "        Cy0, Cx0 = (bot_0, right_0) #By + height, Bx\n",
    "        Dy0, Dx0 = (bot_0, left_0) #Cy, Ax\n",
    "        # used in testing, where each batch is a sample of different shapes\n",
    "        counts = K.ones_like( x[:1,...,:1] )\n",
    "        count_ii = self._initialize_ii_buffer( counts )\n",
    "        # compute winsize if necessary\n",
    "        counts_2d = count_ii[:,Ay:Ay0, Ax:Ax0] \\\n",
    "                  + count_ii[:,Cy:Cy0, Cx:Cx0] \\\n",
    "                  - count_ii[:,By:By0, Bx:Bx0] \\\n",
    "                  - count_ii[:,Dy:Dy0, Dx:Dx0]\n",
    "        # 2. compute summed feature\n",
    "        sum_x_2d = x_ii[:,Ay:Ay0, Ax:Ax0] \\\n",
    "                 + x_ii[:,Cy:Cy0, Cx:Cx0] \\\n",
    "                 - x_ii[:,By:By0, Bx:Bx0] \\\n",
    "                 - x_ii[:,Dy:Dy0, Dx:Dx0]\n",
    "        # 3. compute average feature\n",
    "        avg_x_2d = sum_x_2d / counts_2d\n",
    "        return avg_x_2d\n",
    "    \n",
    "    def call( self, x ) :\n",
    "        x_win_avgs = []\n",
    "        # 1. compute corr(x, window_mean) for different sizes\n",
    "        # 1.1 compute integral image buffer\n",
    "        x_ii = self._initialize_ii_buffer( x )\n",
    "        for hw in self.window_size_list :\n",
    "            if isinstance( hw, int ) :\n",
    "                height = width = hw\n",
    "            else :\n",
    "                height, width = hw[:2]\n",
    "            this_avg = self._compute_for_one_size( x, x_ii, height, width )\n",
    "            if ( self.minus_original ) :\n",
    "                x_win_avgs.append( this_avg-x )\n",
    "            else :\n",
    "                x_win_avgs.append( this_avg )\n",
    "        # 2. compute corr(x, global_mean)\n",
    "        if ( self.include_global ) :\n",
    "            if ( self.minus_original ) :\n",
    "                mu = K.mean( x, axis=(1,2), keepdims=True )\n",
    "                x_win_avgs.append( mu-x )\n",
    "            else :\n",
    "                mu = K.mean( x, axis=(1,2), keepdims=True ) * K.ones_like(x)\n",
    "                x_win_avgs.append( mu )\n",
    "        if self.output_mode == '4d' :\n",
    "            return K.concatenate( x_win_avgs, axis=-1 )\n",
    "        elif self.output_mode == '5d' :\n",
    "            return K.stack( x_win_avgs, axis=1 )\n",
    "        else :\n",
    "            raise (NotImplementedError, \"ERROR: unknown output_mode={}\".format( self.output_mode ))\n",
    "            \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch_size, num_rows, num_cols, num_filts = input_shape\n",
    "        if self.output_mode == '4d' :\n",
    "            return ( batch_size, num_rows, num_cols, (self.num_woi+int(self.include_global))*num_filts )\n",
    "        else :\n",
    "            return ( batch_size, self.num_woi+int(self.include_global), num_rows, num_cols, num_filts )\n",
    "\n",
    "def create_manTraNet_model( Featex, pool_size_list=[7,15,31], is_dynamic_shape=True, apply_normalization=True ) :\n",
    "    \"\"\"\n",
    "    Create ManTra-Net from a pretrained IMC-Featex model\n",
    "    \"\"\"\n",
    "    img_in = Input(shape=(None,None,3), name='img_in' )\n",
    "    rf = Featex( img_in )\n",
    "    rf = Conv2D( 64, (1,1),\n",
    "                 activation=None, # no need to use tanh if sf is L2normalized\n",
    "                 use_bias=False,\n",
    "                 kernel_constraint = unit_norm( axis=-2 ),\n",
    "                 name='outlierTrans',\n",
    "                 padding = 'same' )(rf)\n",
    "    bf = BatchNormalization( axis=-1, name='bnorm', center=False, scale=False )(rf)\n",
    "    devf5d = NestedWindowAverageFeatExtrator(window_size_list=pool_size_list,\n",
    "                                             output_mode='5d',\n",
    "                                             minus_original=True,\n",
    "                                             name='nestedAvgFeatex' )( bf )\n",
    "    if ( apply_normalization ) :\n",
    "        sigma = GlobalStd2D( name='glbStd' )( bf )\n",
    "        sigma5d = Lambda( lambda t : K.expand_dims( t, axis=1 ), name='expTime')( sigma )\n",
    "        devf5d = Lambda( lambda vs : K.abs(vs[0]/vs[1]), name='divStd' )([devf5d, sigma5d])\n",
    "    # convert back to 4d\n",
    "    devf = ConvLSTM2D( 8, (7,7),\n",
    "                       activation='tanh',\n",
    "                       recurrent_activation='hard_sigmoid',\n",
    "                       padding='same',\n",
    "                       name='cLSTM',\n",
    "                       return_sequences=False )(devf5d)\n",
    "    pred_out = Conv2D(1, (7,7), padding='same', activation='sigmoid', name='pred')( devf )\n",
    "    return Model( inputs=img_in, outputs=pred_out, name='sigNet' )\n",
    "\n",
    "def create_model( IMC_model_idx, freeze_featex, window_size_list ) :\n",
    "    type_idx = IMC_model_idx if IMC_model_idx < 4 else 2\n",
    "    Featex = create_featex_vgg16_base( type_idx )\n",
    "    if freeze_featex :\n",
    "        print (\"INFO: freeze feature extraction part, trainable=False\")\n",
    "        Featex.trainable = False\n",
    "    else :\n",
    "        print (\"INFO: unfreeze feature extraction part, trainable=True\")\n",
    "\n",
    "    if ( len( window_size_list ) == 4 ) :\n",
    "        for ly in Featex.layers[:5] :\n",
    "            ly.trainable = False\n",
    "            print (\"INFO: freeze\", ly.name)\n",
    "    model = create_manTraNet_model( Featex,\n",
    "                                    pool_size_list=window_size_list,\n",
    "                                    is_dynamic_shape=True,\n",
    "                                    apply_normalization=True, )\n",
    "    return model\n",
    "\n",
    "def load_pretrain_model_by_index( pretrain_index, model_dir ) :\n",
    "    if ( pretrain_index == 4 ) :\n",
    "        IMC_model_idx, freeze_featex, window_size_list  = 2, False, [7, 15, 31]\n",
    "    else :\n",
    "        IMC_model_idx, freeze_featex, window_size_list  = pretrain_index, False, [7, 15, 31, 63]\n",
    "    single_gpu_model = create_model( IMC_model_idx, freeze_featex, window_size_list )\n",
    "    weight_file = \"{}/ManTraNet_Ptrain{}.h5\".format( model_dir, pretrain_index )\n",
    "    assert os.path.isfile(weight_file), \"ERROR: fail to locate the pretrained weight file\"\n",
    "    single_gpu_model.load_weights( weight_file )\n",
    "    return single_gpu_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "INFO: use activation in the last CONV=None\n",
      "INFO: unfreeze feature extraction part, trainable=True\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_in (InputLayer)             (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Featex (Model)                  (None, None, None, 1 920861      img_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "outlierTrans (Conv2D)           (None, None, None, 6 8192        Featex[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm (BatchNormalization)      (None, None, None, 6 128         outlierTrans[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "glbStd (GlobalStd2D)            (None, 1, 1, 64)     64          bnorm[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "nestedAvgFeatex (NestedWindowAv (None, 4, None, None 0           bnorm[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "expTime (Lambda)                (None, 1, 1, 1, 64)  0           glbStd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "divStd (Lambda)                 (None, 4, None, None 0           nestedAvgFeatex[0][0]            \n",
      "                                                                 expTime[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cLSTM (ConvLSTM2D)              (None, None, None, 8 112928      divStd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pred (Conv2D)                   (None, None, None, 1 393         cLSTM[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,042,566\n",
      "Trainable params: 1,042,438\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/ubuntu/')\n",
    "manTraNet_root = './ManTraNet/'\n",
    "manTraNet_srcDir = os.path.join( manTraNet_root, 'src' )\n",
    "sys.path.insert( 0, manTraNet_srcDir )\n",
    "manTraNet_modelDir = os.path.join( manTraNet_root, 'pretrained_weights' )\n",
    "manTraNet_dataDir = os.path.join( manTraNet_root, 'data' )\n",
    "\n",
    "\n",
    "os.chdir('/home/ubuntu/')\n",
    "#manTraNet = load_pretrain_model_by_index(1, manTraNet_modelDir)\n",
    "single_gpu_model = create_model(2, False, [7, 15, 31])\n",
    "single_gpu_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "single_gpu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[:2]\n",
    "y = Y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 620/8275 [=>............................] - ETA: 39:21 - loss: 0.6941 - acc: 0.5607"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-21f137c8a7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msingle_gpu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "single_gpu_model.fit(X_train[:], Y_train[:], epochs=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
