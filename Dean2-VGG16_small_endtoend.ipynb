{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.layers import Layer, Input, GlobalAveragePooling2D, Lambda, Dense\n",
    "from keras.layers import ConvLSTM2D, Conv2D, AveragePooling2D, BatchNormalization\n",
    "from keras.constraints import unit_norm, non_neg\n",
    "from keras.activations import softmax\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.constraints import Constraint\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import _Conv\n",
    "from keras.legacy import interfaces\n",
    "from keras.engine import InputSpec\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DSymPadding( _Conv ) :\n",
    "    @interfaces.legacy_conv2d_support\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 padding='same',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Conv2DSymPadding, self).__init__(\n",
    "            rank=2,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "    def get_config(self):\n",
    "        config = super(Conv2DSymPadding, self).get_config()\n",
    "        config.pop('rank')\n",
    "        return config\n",
    "    def call( self, inputs ) :\n",
    "        if ( isinstance( self.kernel_size, tuple ) ) :\n",
    "            kh, kw = self.kernel_size\n",
    "        else :\n",
    "            kh = kw = self.kernel_size\n",
    "        ph, pw = kh//2, kw//2\n",
    "        inputs_pad = tf.pad( inputs, [[0,0],[ph,ph],[pw,pw],[0,0]], mode='symmetric' )\n",
    "        outputs = K.conv2d(\n",
    "                inputs_pad,\n",
    "                self.kernel,\n",
    "                strides=self.strides,\n",
    "                padding='valid',\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayarConstraint( Constraint ) :\n",
    "    def __init__( self ) :\n",
    "        self.mask = None\n",
    "    def _initialize_mask( self, w ) :\n",
    "        nb_rows, nb_cols, nb_inputs, nb_outputs = K.int_shape(w)\n",
    "        m = np.zeros([nb_rows, nb_cols, nb_inputs, nb_outputs]).astype('float32')\n",
    "        m[nb_rows//2,nb_cols//2] = 1.\n",
    "        self.mask = K.variable( m, dtype='float32' )\n",
    "        return\n",
    "    def __call__( self, w ) :\n",
    "        if self.mask is None :\n",
    "            self._initialize_mask(w)\n",
    "        w *= (1-self.mask)\n",
    "        rest_sum = K.sum( w, axis=(0,1), keepdims=True)\n",
    "        w /= rest_sum + K.epsilon()\n",
    "        w -= self.mask\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ii layer\n",
    "\n",
    "class IlluminationInvariant(Layer):\n",
    "    # constructor\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(IlluminationInvariant, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable alpha for this layer.\n",
    "        self.alpha = self.add_weight(name='alpha', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(IlluminationInvariant, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, img):\n",
    "        assert isinstance(img, np.ndarray)\n",
    "        assert(img.shape[2] == 3)\n",
    "        tmp = (0.5 + K.log(img[:, :, 1] / float(255)) -\n",
    "                self.alpha * K.log(img[:, :, 2] / float(255)) -\n",
    "                (1 - self.alpha) * K.log(img[:, :, 0] / float(255)))\n",
    "        return tmp\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illumination invariant computation\n",
    "def rgb2ii(img, alpha):\n",
    "    \"\"\"Convert RGB image to illumination invariant image.\"\"\"\n",
    "    ii_image = (0.5 + np.log(img[:, :, 1] / float(255)) -\n",
    "                alpha * np.log(img[:, :, 2] / float(255)) -\n",
    "                (1 - alpha) * np.log(img[:, :, 0] / float(255)))\n",
    "    return ii_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedConv2D(Conv2DSymPadding) :\n",
    "    def __init__(self, filters,\n",
    "                 select = 'all',\n",
    "                 kernel_size=(5,5),\n",
    "                 strides=(1,1),\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1,1),\n",
    "                 activation=None,\n",
    "                 padding='same',\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        self.select = select\n",
    "        super(CombinedConv2D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=(5,5),\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=None,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=None,\n",
    "            **kwargs)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        \n",
    "    def _get_srm_list( self ) :\n",
    "        # srm kernel 1                                                                                                                                \n",
    "        srm1 = np.zeros([5,5]).astype('float32')\n",
    "        srm1[1:-1,1:-1] = np.array([[-1, 2, -1],\n",
    "                                    [2, -4, 2],\n",
    "                                    [-1, 2, -1]] )\n",
    "        srm1 /= 4.\n",
    "        # srm kernel 2                                                                                                                                \n",
    "        srm2 = np.array([[-1, 2, -2, 2, -1],\n",
    "                         [2, -6, 8, -6, 2],\n",
    "                         [-2, 8, -12, 8, -2],\n",
    "                         [2, -6, 8, -6, 2],\n",
    "                         [-1, 2, -2, 2, -1]]).astype('float32')\n",
    "        srm2 /= 12.\n",
    "        # srm kernel 3                                                                                                                                \n",
    "        srm3 = np.zeros([5,5]).astype('float32')\n",
    "        srm3[2,1:-1] = np.array([1,-2,1])\n",
    "        srm3 /= 2.\n",
    "        return [ srm1, srm2, srm3 ]\n",
    "    \n",
    "    def _build_SRM_kernel( self ) :\n",
    "        kernel = []\n",
    "        srm_list = self._get_srm_list()\n",
    "        for idx, srm in enumerate( srm_list ):\n",
    "            for ch in range(3) :\n",
    "                this_ch_kernel = np.zeros([5,5,3]).astype('float32')\n",
    "                this_ch_kernel[:,:,ch] = srm\n",
    "                kernel.append( this_ch_kernel )\n",
    "        kernel = np.stack( kernel, axis=-1 )\n",
    "        srm_kernel = K.variable( kernel, dtype='float32', name='srm' )\n",
    "        return srm_kernel\n",
    "    \n",
    "    def build( self, input_shape ) :\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise( ValueError, 'The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        \n",
    "        # 1. regular conv kernels, fully trainable                                                                                                    \n",
    "        filters = self.filters - 9 - 3\n",
    "        if filters >= 1 :\n",
    "            regular_kernel_shape = self.kernel_size + (input_dim, filters)\n",
    "            self.regular_kernel = self.add_weight(shape=regular_kernel_shape,\n",
    "                                          initializer=self.kernel_initializer,\n",
    "                                          name='regular_kernel',\n",
    "                                          regularizer=self.kernel_regularizer,\n",
    "                                          constraint=self.kernel_constraint)\n",
    "        else :\n",
    "            self.regular_kernel = None\n",
    "            \n",
    "        # 2. SRM kernels, not trainable                                                                  \n",
    "        self.srm_kernel = self._build_SRM_kernel()\n",
    "        \n",
    "        # 3. bayar kernels, trainable but under constraint                                                                                            \n",
    "        bayar_kernel_shape = self.kernel_size + (input_dim, 3)\n",
    "        self.bayar_kernel = self.add_weight(shape=bayar_kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='bayar_kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=BayarConstraint())\n",
    "        \n",
    "        # 5. II kernels, trainable parameters\n",
    "        #ii_kernel_shape = self.alpha\n",
    "        \n",
    "        # 6. collect all kernels\n",
    "        if ( self.regular_kernel is not None ) :\n",
    "            if self.select is 'all':\n",
    "                all_kernels = [ self.regular_kernel,\n",
    "                                self.srm_kernel,\n",
    "                                self.bayar_kernel]\n",
    "            elif self.select is 'reg':\n",
    "                all_kernels = [self.regular_kernel]\n",
    "            elif self.select is 'srm':\n",
    "                all_kernels = [self.srm_kernel]\n",
    "            elif self.select is 'bayar':\n",
    "                all_kernels = [self.bayar_kernel]\n",
    "            else :\n",
    "                all_kernels = [ self.srm_kernel,\n",
    "                                self.bayar_kernel]\n",
    "        self.kernel = K.concatenate( all_kernels, axis=-1 )\n",
    "        \n",
    "        # Set input spec.                                                                                                                             \n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featex_vgg7_base( type=1 ) :\n",
    "    base = 4\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    # block 3\n",
    "    bname = 'b3'\n",
    "    nb_filters = 4 * base # 96\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c3')( x )\n",
    "    # block 4\n",
    "    bname = 'b4'\n",
    "    nb_filters = 8 * base # 128\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c3')( x )\n",
    "    # block 5/bottle-neck \n",
    "    bname = 'b5'\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    print (\"INFO: use activation in the last CONV={}\".format( activation ))\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n",
    "\n",
    "class GlobalStd2D( Layer ) :\n",
    "    '''Custom Keras Layer to compute sample-wise feature deviation\n",
    "    '''\n",
    "    def __init__( self, min_std_val=1e-5, **kwargs ) :\n",
    "        self.min_std_val = min_std_val\n",
    "        super( GlobalStd2D, self ).__init__( **kwargs )\n",
    "    def build( self, input_shape ) :\n",
    "        nb_feats = input_shape[-1]\n",
    "        std_shape = ( 1,1,1, nb_feats )\n",
    "        self.min_std = self.add_weight( shape=std_shape,\n",
    "                                        initializer=Constant(self.min_std_val),\n",
    "                                        name='min_std',\n",
    "                                        constraint=non_neg() )\n",
    "        self.built = True\n",
    "        return\n",
    "    def call( self, x ) :\n",
    "        x_std = K.std( x, axis=(1,2), keepdims=True )\n",
    "        x_std = K.maximum( x_std, self.min_std_val/10. + self.min_std )\n",
    "        return x_std\n",
    "    def compute_output_shape( self, input_shape ) :\n",
    "        return (input_shape[0], 1, 1, input_shape[-1] )\n",
    "\n",
    "class NestedWindowAverageFeatExtrator( Layer ) :\n",
    "    '''Custom Keras Layer of NestedWindowAverageFeatExtrator\n",
    "    '''\n",
    "    def __init__( self,\n",
    "                  window_size_list,\n",
    "                  output_mode='5d',\n",
    "                  minus_original=False,\n",
    "                  include_global=True,\n",
    "                  **kwargs ) :\n",
    "        '''\n",
    "        INPUTS:\n",
    "            win_size_list = list of int or tuples, each elem indicate a winsize of interest\n",
    "            output_mode = '5d' or '4d', where\n",
    "                          '5d' merges all win_avgs along a new time axis\n",
    "                          '4d' merges all win_avgs along the existing feat axis\n",
    "        '''\n",
    "        self.window_size_list = window_size_list\n",
    "        assert output_mode in ['5d','4d'], \"ERROR: unkown output mode={}\".format( output_mode )\n",
    "        self.output_mode = output_mode\n",
    "        self.minus_original = minus_original\n",
    "        self.include_global = include_global\n",
    "        super(NestedWindowAverageFeatExtrator, self).__init__(**kwargs)\n",
    "        \n",
    "    def build( self, input_shape ) :\n",
    "        self.num_woi = len( self.window_size_list )\n",
    "        self.count_ii = None\n",
    "        self.lut = dict()\n",
    "        self.built = True\n",
    "        self.max_wh, self.max_ww = self._get_max_size()\n",
    "        return\n",
    "    \n",
    "    def _initialize_ii_buffer( self, x ) :\n",
    "        x_pad = K.spatial_2d_padding( x, ((self.max_wh//2+1,self.max_wh//2+1), (self.max_ww//2+1,self.max_ww//2+1)) )\n",
    "        ii_x  = K.cumsum( x_pad, axis=1 )\n",
    "        ii_x2 = K.cumsum( ii_x, axis=2 )\n",
    "        return ii_x2\n",
    "    \n",
    "    def _get_max_size( self ) :\n",
    "        mh, mw = 0, 0\n",
    "        for hw in self.window_size_list :\n",
    "            if ( isinstance( hw, int ) ) :\n",
    "                h = w = hw\n",
    "            else :\n",
    "                h, w = hw[:2]\n",
    "            mh = max( h, mh )\n",
    "            mw = max( w, mw )\n",
    "        return mh, mw\n",
    "    \n",
    "    def _compute_for_one_size( self, x, x_ii, height, width ) :\n",
    "        # 1. compute valid counts for this key\n",
    "        top   = self.max_wh//2 - height//2\n",
    "        bot   = top + height\n",
    "        left  = self.max_ww//2 - width //2\n",
    "        right = left + width\n",
    "        Ay, Ax = (top, left) #self.max_wh, self.max_ww\n",
    "        By, Bx = (top, right) # Ay, Ax + width\n",
    "        Cy, Cx = (bot, right) #By + height, Bx\n",
    "        Dy, Dx = (bot, left) #Cy, Ax\n",
    "        ii_key = (height,width)\n",
    "        top_0   = -self.max_wh//2 - height//2 - 1\n",
    "        bot_0   = top_0 + height\n",
    "        left_0  = -self.max_ww//2 - width//2 - 1\n",
    "        right_0 = left_0 + width\n",
    "        Ay0, Ax0 = (top_0, left_0) #self.max_wh, self.max_ww\n",
    "        By0, Bx0 = (top_0, right_0) # Ay, Ax + width\n",
    "        Cy0, Cx0 = (bot_0, right_0) #By + height, Bx\n",
    "        Dy0, Dx0 = (bot_0, left_0) #Cy, Ax\n",
    "        # used in testing, where each batch is a sample of different shapes\n",
    "        counts = K.ones_like( x[:1,...,:1] )\n",
    "        count_ii = self._initialize_ii_buffer( counts )\n",
    "        # compute winsize if necessary\n",
    "        counts_2d = count_ii[:,Ay:Ay0, Ax:Ax0] \\\n",
    "                  + count_ii[:,Cy:Cy0, Cx:Cx0] \\\n",
    "                  - count_ii[:,By:By0, Bx:Bx0] \\\n",
    "                  - count_ii[:,Dy:Dy0, Dx:Dx0]\n",
    "        # 2. compute summed feature\n",
    "        sum_x_2d = x_ii[:,Ay:Ay0, Ax:Ax0] \\\n",
    "                 + x_ii[:,Cy:Cy0, Cx:Cx0] \\\n",
    "                 - x_ii[:,By:By0, Bx:Bx0] \\\n",
    "                 - x_ii[:,Dy:Dy0, Dx:Dx0]\n",
    "        # 3. compute average feature\n",
    "        avg_x_2d = sum_x_2d / counts_2d\n",
    "        return avg_x_2d\n",
    "    \n",
    "    def call( self, x ) :\n",
    "        x_win_avgs = []\n",
    "        # 1. compute corr(x, window_mean) for different sizes\n",
    "        # 1.1 compute integral image buffer\n",
    "        x_ii = self._initialize_ii_buffer( x )\n",
    "        for hw in self.window_size_list :\n",
    "            if isinstance( hw, int ) :\n",
    "                height = width = hw\n",
    "            else :\n",
    "                height, width = hw[:2]\n",
    "            this_avg = self._compute_for_one_size( x, x_ii, height, width )\n",
    "            if ( self.minus_original ) :\n",
    "                x_win_avgs.append( this_avg-x )\n",
    "            else :\n",
    "                x_win_avgs.append( this_avg )\n",
    "        # 2. compute corr(x, global_mean)\n",
    "        if ( self.include_global ) :\n",
    "            if ( self.minus_original ) :\n",
    "                mu = K.mean( x, axis=(1,2), keepdims=True )\n",
    "                x_win_avgs.append( mu-x )\n",
    "            else :\n",
    "                mu = K.mean( x, axis=(1,2), keepdims=True ) * K.ones_like(x)\n",
    "                x_win_avgs.append( mu )\n",
    "        if self.output_mode == '4d' :\n",
    "            return K.concatenate( x_win_avgs, axis=-1 )\n",
    "        elif self.output_mode == '5d' :\n",
    "            return K.stack( x_win_avgs, axis=1 )\n",
    "        else :\n",
    "            raise (NotImplementedError, \"ERROR: unknown output_mode={}\".format( self.output_mode ))\n",
    "            \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch_size, num_rows, num_cols, num_filts = input_shape\n",
    "        if self.output_mode == '4d' :\n",
    "            return ( batch_size, num_rows, num_cols, (self.num_woi+int(self.include_global))*num_filts )\n",
    "        else :\n",
    "            return ( batch_size, self.num_woi+int(self.include_global), num_rows, num_cols, num_filts )\n",
    "\n",
    "def create_manTraNet_model( Featex, pool_size_list=[7,15,31], is_dynamic_shape=True, apply_normalization=True ) :\n",
    "    \"\"\"\n",
    "    Create ManTra-Net from a pretrained IMC-Featex model\n",
    "    \"\"\"\n",
    "    img_in = Input(shape=(None,None,3), name='img_in' )\n",
    "    rf = Featex( img_in )\n",
    "    rf = Conv2D( 64, (1,1),\n",
    "                 activation=None, # no need to use tanh if sf is L2normalized\n",
    "                 use_bias=False,\n",
    "                 kernel_constraint = unit_norm( axis=-2 ),\n",
    "                 name='outlierTrans',\n",
    "                 padding = 'same' )(rf)\n",
    "    bf = BatchNormalization( axis=-1, name='bnorm', center=False, scale=False )(rf)\n",
    "    devf5d = NestedWindowAverageFeatExtrator(window_size_list=pool_size_list,\n",
    "                                             output_mode='5d',\n",
    "                                             minus_original=True,\n",
    "                                             name='nestedAvgFeatex' )( bf )\n",
    "    if ( apply_normalization ) :\n",
    "        sigma = GlobalStd2D( name='glbStd' )( bf )\n",
    "        sigma5d = Lambda( lambda t : K.expand_dims( t, axis=1 ), name='expTime')( sigma )\n",
    "        devf5d = Lambda( lambda vs : K.abs(vs[0]/vs[1]), name='divStd' )([devf5d, sigma5d])\n",
    "    # convert back to 4d\n",
    "    devf = ConvLSTM2D( 8, (7,7),\n",
    "                       activation='tanh',\n",
    "                       recurrent_activation='hard_sigmoid',\n",
    "                       padding='same',\n",
    "                       name='cLSTM',\n",
    "                       return_sequences=False )(devf5d)\n",
    "    pred_out = Conv2D(1, (7,7), padding='same', activation='sigmoid', name='pred')( devf )\n",
    "    return Model( inputs=img_in, outputs=pred_out, name='sigNet' )\n",
    "\n",
    "def create_model( IMC_model_idx, freeze_featex, window_size_list ) :\n",
    "    type_idx = IMC_model_idx if IMC_model_idx < 4 else 2\n",
    "    Featex = create_featex_vgg7_base( type_idx )\n",
    "    if freeze_featex :\n",
    "        print (\"INFO: freeze feature extraction part, trainable=False\")\n",
    "        Featex.trainable = False\n",
    "    else :\n",
    "        print (\"INFO: unfreeze feature extraction part, trainable=True\")\n",
    "\n",
    "    if ( len( window_size_list ) == 4 ) :\n",
    "        for ly in Featex.layers[:5] :\n",
    "            ly.trainable = False\n",
    "            print (\"INFO: freeze\", ly.name)\n",
    "    model = create_manTraNet_model( Featex,\n",
    "                                    pool_size_list=window_size_list,\n",
    "                                    is_dynamic_shape=True,\n",
    "                                    apply_normalization=True, )\n",
    "    return model\n",
    "\n",
    "def load_pretrain_model_by_index( pretrain_index, model_dir ) :\n",
    "    if ( pretrain_index == 4 ) :\n",
    "        IMC_model_idx, freeze_featex, window_size_list  = 2, False, [7, 15, 31]\n",
    "    else :\n",
    "        IMC_model_idx, freeze_featex, window_size_list  = pretrain_index, False, [7, 15, 31, 63]\n",
    "    single_gpu_model = create_model( IMC_model_idx, freeze_featex, window_size_list )\n",
    "    weight_file = \"{}/ManTraNet_Ptrain{}.h5\".format( model_dir, pretrain_index )\n",
    "    assert os.path.isfile(weight_file), \"ERROR: fail to locate the pretrained weight file\"\n",
    "    single_gpu_model.load_weights( weight_file )\n",
    "    return single_gpu_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "INFO: use activation in the last CONV=None\n",
      "INFO: unfreeze feature extraction part, trainable=True\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_in (InputLayer)             (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Featex (Model)                  (None, None, None, 3 40177       img_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "outlierTrans (Conv2D)           (None, None, None, 6 2048        Featex[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm (BatchNormalization)      (None, None, None, 6 128         outlierTrans[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "glbStd (GlobalStd2D)            (None, 1, 1, 64)     64          bnorm[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "nestedAvgFeatex (NestedWindowAv (None, 4, None, None 0           bnorm[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "expTime (Lambda)                (None, 1, 1, 1, 64)  0           glbStd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "divStd (Lambda)                 (None, 4, None, None 0           nestedAvgFeatex[0][0]            \n",
      "                                                                 expTime[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cLSTM (ConvLSTM2D)              (None, None, None, 8 112928      divStd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pred (Conv2D)                   (None, None, None, 1 393         cLSTM[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 155,738\n",
      "Trainable params: 155,610\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/ubuntu/')\n",
    "manTraNet_root = './ManTraNet/'\n",
    "manTraNet_srcDir = os.path.join( manTraNet_root, 'src' )\n",
    "sys.path.insert( 0, manTraNet_srcDir )\n",
    "manTraNet_modelDir = os.path.join( manTraNet_root, 'pretrained_weights' )\n",
    "manTraNet_dataDir = os.path.join( manTraNet_root, 'data' )\n",
    "\n",
    "\n",
    "os.chdir('/home/ubuntu/')\n",
    "#manTraNet = load_pretrain_model_by_index(1, manTraNet_modelDir)\n",
    "single_gpu_model = create_model(2, False, [7, 15, 31])\n",
    "single_gpu_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "single_gpu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train_2.npy')\n",
    "Y_train = np.load('Y_train_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"output/vgg7_small_endtoend_data2-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "single_gpu_model.fit(X_train, Y_train, epochs=20, batch_size=10, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: use activation in the last CONV=None\n",
      "INFO: unfreeze feature extraction part, trainable=True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_in (InputLayer)             (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Featex (Model)                  (None, None, None, 3 40177       img_in[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "outlierTrans (Conv2D)           (None, None, None, 6 2048        Featex[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bnorm (BatchNormalization)      (None, None, None, 6 128         outlierTrans[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "glbStd (GlobalStd2D)            (None, 1, 1, 64)     64          bnorm[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "nestedAvgFeatex (NestedWindowAv (None, 4, None, None 0           bnorm[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "expTime (Lambda)                (None, 1, 1, 1, 64)  0           glbStd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "divStd (Lambda)                 (None, 4, None, None 0           nestedAvgFeatex[0][0]            \n",
      "                                                                 expTime[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cLSTM (ConvLSTM2D)              (None, None, None, 8 112928      divStd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pred (Conv2D)                   (None, None, None, 1 393         cLSTM[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 155,738\n",
      "Trainable params: 155,610\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/ubuntu/')\n",
    "\n",
    "#manTraNet = load_pretrain_model_by_index(1, manTraNet_modelDir)\n",
    "single_gpu_model = create_model(2, False, [7, 15, 31])\n",
    "weight_file = \"output/vgg7_small_endtoend_data2-20.hdf5\"\n",
    "single_gpu_model.load_weights( weight_file )\n",
    "single_gpu_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "single_gpu_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 69s 69ms/step\n",
      "\n",
      "Loss = 0.3726019661426544\n",
      "Test Accuracy = 0.8961729717254638\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load('X_test_1.npy')\n",
    "Y_test = np.load('Y_test_1.npy')\n",
    "preds = single_gpu_model.evaluate(X_test, Y_test, batch_size=8, verbose=1, sample_weight=None)\n",
    "### END CODE HERE ###\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=single_gpu_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test.reshape((Y_test.shape[0] * Y_test.shape[1] * Y_test.shape[2]))\n",
    "Y_test = Y_test > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50176000,) float32\n",
      "(50176000,) bool\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "Y_pred = y_pred.copy()\n",
    "Y_pred = Y_pred.reshape((Y_pred.shape[0] * Y_pred.shape[1] * Y_pred.shape[2]))\n",
    "print(Y_pred.shape, Y_pred.dtype)\n",
    "print(Y_test.shape, Y_test.dtype)\n",
    "#cm=confusion_matrix(Y_test,Y_pred)\n",
    "#print(cm)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_pred)\n",
    "AUC = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export and save data\n",
    "import scipy.io as sio\n",
    "sio.savemat('dean2_VGG7_small_data2',{'tpr':tpr, 'fpr':fpr, 'AUC': AUC, 'TestLoss':preds[0], 'TestACC':preds[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
