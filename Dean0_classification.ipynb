{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.layers import Layer, Input, GlobalAveragePooling2D, Lambda, Dense, Flatten, Dropout\n",
    "from keras.layers import ConvLSTM2D, Conv2D, AveragePooling2D, BatchNormalization, MaxPooling2D, Concatenate\n",
    "from keras.regularizers import l1\n",
    "from keras.constraints import unit_norm, non_neg\n",
    "from keras.activations import softmax\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.constraints import Constraint\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import _Conv\n",
    "from keras.legacy import interfaces\n",
    "from keras.engine import InputSpec\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DSymPadding( _Conv ) :\n",
    "    @interfaces.legacy_conv2d_support\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 activation=None,\n",
    "                 padding='same',\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(Conv2DSymPadding, self).__init__(\n",
    "            rank=2,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "    def get_config(self):\n",
    "        config = super(Conv2DSymPadding, self).get_config()\n",
    "        config.pop('rank')\n",
    "        return config\n",
    "    def call( self, inputs ) :\n",
    "        if ( isinstance( self.kernel_size, tuple ) ) :\n",
    "            kh, kw = self.kernel_size\n",
    "        else :\n",
    "            kh = kw = self.kernel_size\n",
    "        ph, pw = kh//2, kw//2\n",
    "        inputs_pad = tf.pad( inputs, [[0,0],[ph,ph],[pw,pw],[0,0]], mode='symmetric' )\n",
    "        outputs = K.conv2d(\n",
    "                inputs_pad,\n",
    "                self.kernel,\n",
    "                strides=self.strides,\n",
    "                padding='valid',\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayarConstraint( Constraint ) :\n",
    "    def __init__( self ) :\n",
    "        self.mask = None\n",
    "    def _initialize_mask( self, w ) :\n",
    "        nb_rows, nb_cols, nb_inputs, nb_outputs = K.int_shape(w)\n",
    "        m = np.zeros([nb_rows, nb_cols, nb_inputs, nb_outputs]).astype('float32')\n",
    "        m[nb_rows//2,nb_cols//2] = 1.\n",
    "        self.mask = K.variable( m, dtype='float32' )\n",
    "        return\n",
    "    def __call__( self, w ) :\n",
    "        if self.mask is None :\n",
    "            self._initialize_mask(w)\n",
    "        w *= (1-self.mask)\n",
    "        rest_sum = K.sum( w, axis=(0,1), keepdims=True)\n",
    "        w /= rest_sum + K.epsilon()\n",
    "        w -= self.mask\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illumination invariant computation\n",
    "def rgb2ii(img, alpha):\n",
    "    \"\"\"Convert RGB image to illumination invariant image.\"\"\"\n",
    "    ii_image = (0.5 + np.log(img[:, :, 1] / float(255)) -\n",
    "                alpha * np.log(img[:, :, 2] / float(255)) -\n",
    "                (1 - alpha) * np.log(img[:, :, 0] / float(255)))\n",
    "    return ii_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedConv2D(Conv2DSymPadding) :\n",
    "    def __init__(self, filters,\n",
    "                 select = 'all',\n",
    "                 kernel_size=(5,5),\n",
    "                 strides=(1,1),\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1,1),\n",
    "                 activation=None,\n",
    "                 padding='same',\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        self.select = select\n",
    "        super(CombinedConv2D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=(5,5),\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=None,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=None,\n",
    "            **kwargs)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        \n",
    "    def _get_srm_list( self ) :\n",
    "        # srm kernel 1                                                                                                                                \n",
    "        srm1 = np.zeros([5,5]).astype('float32')\n",
    "        srm1[1:-1,1:-1] = np.array([[-1, 2, -1],\n",
    "                                    [2, -4, 2],\n",
    "                                    [-1, 2, -1]] )\n",
    "        srm1 /= 4.\n",
    "        # srm kernel 2                                                                                                                                \n",
    "        srm2 = np.array([[-1, 2, -2, 2, -1],\n",
    "                         [2, -6, 8, -6, 2],\n",
    "                         [-2, 8, -12, 8, -2],\n",
    "                         [2, -6, 8, -6, 2],\n",
    "                         [-1, 2, -2, 2, -1]]).astype('float32')\n",
    "        srm2 /= 12.\n",
    "        # srm kernel 3                                                                                                                                \n",
    "        srm3 = np.zeros([5,5]).astype('float32')\n",
    "        srm3[2,1:-1] = np.array([1,-2,1])\n",
    "        srm3 /= 2.\n",
    "        return [ srm1, srm2, srm3 ]\n",
    "    \n",
    "    def _build_SRM_kernel( self ) :\n",
    "        kernel = []\n",
    "        srm_list = self._get_srm_list()\n",
    "        for idx, srm in enumerate( srm_list ):\n",
    "            for ch in range(3) :\n",
    "                this_ch_kernel = np.zeros([5,5,3]).astype('float32')\n",
    "                this_ch_kernel[:,:,ch] = srm\n",
    "                kernel.append( this_ch_kernel )\n",
    "        kernel = np.stack( kernel, axis=-1 )\n",
    "        srm_kernel = K.variable( kernel, dtype='float32', name='srm' )\n",
    "        return srm_kernel\n",
    "    \n",
    "    def build( self, input_shape ) :\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise( ValueError, 'The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        \n",
    "        # 1. regular conv kernels, fully trainable                                                                                                    \n",
    "        filters = self.filters - 9 - 3\n",
    "        if filters >= 1 :\n",
    "            regular_kernel_shape = self.kernel_size + (input_dim, filters)\n",
    "            self.regular_kernel = self.add_weight(shape=regular_kernel_shape,\n",
    "                                          initializer=self.kernel_initializer,\n",
    "                                          name='regular_kernel',\n",
    "                                          regularizer=self.kernel_regularizer,\n",
    "                                          constraint=self.kernel_constraint)\n",
    "        else :\n",
    "            self.regular_kernel = None\n",
    "            \n",
    "        # 2. SRM kernels, not trainable                                                                  \n",
    "        self.srm_kernel = self._build_SRM_kernel()\n",
    "        \n",
    "        # 3. bayar kernels, trainable but under constraint                                                                                            \n",
    "        bayar_kernel_shape = self.kernel_size + (input_dim, 3)\n",
    "        self.bayar_kernel = self.add_weight(shape=bayar_kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='bayar_kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=BayarConstraint())\n",
    "        \n",
    "        # 6. collect all kernels\n",
    "        if ( self.regular_kernel is not None ) :\n",
    "            if self.select is 'all':\n",
    "                all_kernels = [ self.regular_kernel,\n",
    "                                self.srm_kernel,\n",
    "                                self.bayar_kernel]\n",
    "            elif self.select is 'reg':\n",
    "                all_kernels = [self.regular_kernel]\n",
    "            elif self.select is 'srm':\n",
    "                all_kernels = [self.srm_kernel]\n",
    "            elif self.select is 'bayar':\n",
    "                all_kernels = [self.bayar_kernel]\n",
    "            else :\n",
    "                all_kernels = [ self.srm_kernel,\n",
    "                                self.bayar_kernel]\n",
    "        self.kernel = K.concatenate( all_kernels, axis=-1 )\n",
    "        \n",
    "        # Set input spec.                                                                                                                             \n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedConv2D_copy(Conv2DSymPadding) :\n",
    "    def __init__(self, filters,\n",
    "                 select = 'all',\n",
    "                 kernel_size=(5,5),\n",
    "                 strides=(1,1),\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1,1),\n",
    "                 activation=None,\n",
    "                 padding='same',\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        self.select = select\n",
    "        super(CombinedConv2D, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=(5,5),\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=None,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=None,\n",
    "            **kwargs)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        \n",
    "    def _get_srm_list( self ) :\n",
    "        # srm kernel 1                                                                                                                                \n",
    "        srm1 = np.zeros([5,5]).astype('float32')\n",
    "        srm1[1:-1,1:-1] = np.array([[-1, 2, -1],\n",
    "                                    [2, -4, 2],\n",
    "                                    [-1, 2, -1]] )\n",
    "        srm1 /= 4.\n",
    "        # srm kernel 2                                                                                                                                \n",
    "        srm2 = np.array([[-1, 2, -2, 2, -1],\n",
    "                         [2, -6, 8, -6, 2],\n",
    "                         [-2, 8, -12, 8, -2],\n",
    "                         [2, -6, 8, -6, 2],\n",
    "                         [-1, 2, -2, 2, -1]]).astype('float32')\n",
    "        srm2 /= 12.\n",
    "        # srm kernel 3                                                                                                                                \n",
    "        srm3 = np.zeros([5,5]).astype('float32')\n",
    "        srm3[2,1:-1] = np.array([1,-2,1])\n",
    "        srm3 /= 2.\n",
    "        return [ srm1, srm2, srm3 ]\n",
    "    \n",
    "    def _build_SRM_kernel( self ) :\n",
    "        kernel = []\n",
    "        srm_list = self._get_srm_list()\n",
    "        for idx, srm in enumerate( srm_list ):\n",
    "            for ch in range(3) :\n",
    "                this_ch_kernel = np.zeros([5,5,3]).astype('float32')\n",
    "                this_ch_kernel[:,:,ch] = srm\n",
    "                kernel.append( this_ch_kernel )\n",
    "        kernel = np.stack( kernel, axis=-1 )\n",
    "        srm_kernel = K.variable( kernel, dtype='float32', name='srm' )\n",
    "        return srm_kernel\n",
    "    \n",
    "    def build( self, input_shape ) :\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise( ValueError, 'The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        \n",
    "        # 1. regular conv kernels, fully trainable                                                                                                    \n",
    "        filters = self.filters - 9 - 3\n",
    "        if filters >= 1 :\n",
    "            regular_kernel_shape = self.kernel_size + (input_dim, filters)\n",
    "            self.regular_kernel = self.add_weight(shape=regular_kernel_shape,\n",
    "                                          initializer=self.kernel_initializer,\n",
    "                                          name='regular_kernel',\n",
    "                                          regularizer=self.kernel_regularizer,\n",
    "                                          constraint=self.kernel_constraint)\n",
    "        else :\n",
    "            self.regular_kernel = None\n",
    "            \n",
    "        # 2. SRM kernels, not trainable                                                                  \n",
    "        self.srm_kernel = self._build_SRM_kernel()\n",
    "        \n",
    "        # 3. bayar kernels, trainable but under constraint                                                                                            \n",
    "        bayar_kernel_shape = self.kernel_size + (input_dim, 3)\n",
    "        self.bayar_kernel = self.add_weight(shape=bayar_kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='bayar_kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=BayarConstraint())\n",
    "        \n",
    "        # 6. collect all kernels\n",
    "        if ( self.regular_kernel is not None ) :\n",
    "            if self.select is 'all':\n",
    "                all_kernels = [ self.regular_kernel,\n",
    "                                self.srm_kernel,\n",
    "                                self.bayar_kernel]\n",
    "            elif self.select is 'reg':\n",
    "                all_kernels = [self.regular_kernel]\n",
    "            elif self.select is 'srm':\n",
    "                all_kernels = [self.srm_kernel]\n",
    "            elif self.select is 'bayar':\n",
    "                all_kernels = [self.bayar_kernel]\n",
    "            else :\n",
    "                all_kernels = [ self.srm_kernel,\n",
    "                                self.bayar_kernel]\n",
    "        self.kernel = K.concatenate( all_kernels, axis=-1 )\n",
    "        \n",
    "        # Set input spec.                                                                                                                             \n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featex_vgg7_base1( type=1 ) :\n",
    "    base = 1\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = AveragePooling2D()(x)\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = AveragePooling2D()(x)\n",
    "    # block 3\n",
    "    bname = 'b3'\n",
    "    nb_filters = 4 * base # 96\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = AveragePooling2D()(x)\n",
    "    # block 4/bottle-neck \n",
    "    bname = 'b4'\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    print (\"INFO: use activation in the last CONV={}\".format( activation ))\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n",
    "\n",
    "class GlobalStd2D( Layer ) :\n",
    "    '''Custom Keras Layer to compute sample-wise feature deviation\n",
    "    '''\n",
    "    def __init__( self, min_std_val=1e-5, **kwargs ) :\n",
    "        self.min_std_val = min_std_val\n",
    "        super( GlobalStd2D, self ).__init__( **kwargs )\n",
    "    def build( self, input_shape ) :\n",
    "        nb_feats = input_shape[-1]\n",
    "        std_shape = (1,1,1, nb_feats )\n",
    "        self.min_std = self.add_weight( shape=std_shape,\n",
    "                                        initializer=Constant(self.min_std_val),\n",
    "                                        name='min_std',\n",
    "                                        constraint=non_neg() )\n",
    "        self.built = True\n",
    "        return\n",
    "    def call( self, x ) :\n",
    "        x_std = K.std( x, axis=(1,2), keepdims=True )\n",
    "        x_std = K.maximum( x_std, self.min_std_val/10. + self.min_std )\n",
    "        return x_std\n",
    "    def compute_output_shape( self, input_shape ) :\n",
    "        return (input_shape[0], 1, 1, input_shape[-1] )\n",
    "\n",
    "class NestedWindowAverageFeatExtrator( Layer ) :\n",
    "    '''Custom Keras Layer of NestedWindowAverageFeatExtrator\n",
    "    '''\n",
    "    def __init__( self,\n",
    "                  window_size_list,\n",
    "                  output_mode='5d',\n",
    "                  minus_original=False,\n",
    "                  include_global=True,\n",
    "                  **kwargs ) :\n",
    "        '''\n",
    "        INPUTS:\n",
    "            win_size_list = list of int or tuples, each elem indicate a winsize of interest\n",
    "            output_mode = '5d' or '4d', where\n",
    "                          '5d' merges all win_avgs along a new time axis\n",
    "                          '4d' merges all win_avgs along the existing feat axis\n",
    "        '''\n",
    "        self.window_size_list = window_size_list\n",
    "        assert output_mode in ['5d','4d'], \"ERROR: unkown output mode={}\".format( output_mode )\n",
    "        self.output_mode = output_mode\n",
    "        self.minus_original = minus_original\n",
    "        self.include_global = include_global\n",
    "        super(NestedWindowAverageFeatExtrator, self).__init__(**kwargs)\n",
    "        \n",
    "    def build( self, input_shape ) :\n",
    "        self.num_woi = len( self.window_size_list )\n",
    "        self.count_ii = None\n",
    "        self.lut = dict()\n",
    "        self.built = True\n",
    "        self.max_wh, self.max_ww = self._get_max_size()\n",
    "        return\n",
    "    \n",
    "    def _initialize_ii_buffer( self, x ) :\n",
    "        x_pad = K.spatial_2d_padding( x, ((self.max_wh//2+1,self.max_wh//2+1), (self.max_ww//2+1,self.max_ww//2+1)) )\n",
    "        ii_x  = K.cumsum( x_pad, axis=1 )\n",
    "        ii_x2 = K.cumsum( ii_x, axis=2 )\n",
    "        return ii_x2\n",
    "    \n",
    "    def _get_max_size( self ) :\n",
    "        mh, mw = 0, 0\n",
    "        for hw in self.window_size_list :\n",
    "            if ( isinstance( hw, int ) ) :\n",
    "                h = w = hw\n",
    "            else :\n",
    "                h, w = hw[:2]\n",
    "            mh = max( h, mh )\n",
    "            mw = max( w, mw )\n",
    "        return mh, mw\n",
    "    \n",
    "    def _compute_for_one_size( self, x, x_ii, height, width ) :\n",
    "        # 1. compute valid counts for this key\n",
    "        top   = self.max_wh//2 - height//2\n",
    "        bot   = top + height\n",
    "        left  = self.max_ww//2 - width //2\n",
    "        right = left + width\n",
    "        Ay, Ax = (top, left) #self.max_wh, self.max_ww\n",
    "        By, Bx = (top, right) # Ay, Ax + width\n",
    "        Cy, Cx = (bot, right) #By + height, Bx\n",
    "        Dy, Dx = (bot, left) #Cy, Ax\n",
    "        ii_key = (height,width)\n",
    "        top_0   = -self.max_wh//2 - height//2 - 1\n",
    "        bot_0   = top_0 + height\n",
    "        left_0  = -self.max_ww//2 - width//2 - 1\n",
    "        right_0 = left_0 + width\n",
    "        Ay0, Ax0 = (top_0, left_0) #self.max_wh, self.max_ww\n",
    "        By0, Bx0 = (top_0, right_0) # Ay, Ax + width\n",
    "        Cy0, Cx0 = (bot_0, right_0) #By + height, Bx\n",
    "        Dy0, Dx0 = (bot_0, left_0) #Cy, Ax\n",
    "        # used in testing, where each batch is a sample of different shapes\n",
    "        counts = K.ones_like( x[:1,...,:1] )\n",
    "        count_ii = self._initialize_ii_buffer( counts )\n",
    "        # compute winsize if necessary\n",
    "        counts_2d = count_ii[:,Ay:Ay0, Ax:Ax0] \\\n",
    "                  + count_ii[:,Cy:Cy0, Cx:Cx0] \\\n",
    "                  - count_ii[:,By:By0, Bx:Bx0] \\\n",
    "                  - count_ii[:,Dy:Dy0, Dx:Dx0]\n",
    "        # 2. compute summed feature\n",
    "        sum_x_2d = x_ii[:,Ay:Ay0, Ax:Ax0] \\\n",
    "                 + x_ii[:,Cy:Cy0, Cx:Cx0] \\\n",
    "                 - x_ii[:,By:By0, Bx:Bx0] \\\n",
    "                 - x_ii[:,Dy:Dy0, Dx:Dx0]\n",
    "        # 3. compute average feature\n",
    "        avg_x_2d = sum_x_2d / counts_2d\n",
    "        return avg_x_2d\n",
    "    \n",
    "    def call( self, x ) :\n",
    "        x_win_avgs = []\n",
    "        # 1. compute corr(x, window_mean) for different sizes\n",
    "        # 1.1 compute integral image buffer\n",
    "        x_ii = self._initialize_ii_buffer( x )\n",
    "        for hw in self.window_size_list :\n",
    "            if isinstance( hw, int ) :\n",
    "                height = width = hw\n",
    "            else :\n",
    "                height, width = hw[:2]\n",
    "            this_avg = self._compute_for_one_size( x, x_ii, height, width )\n",
    "            if ( self.minus_original ) :\n",
    "                x_win_avgs.append( this_avg-x )\n",
    "            else :\n",
    "                x_win_avgs.append( this_avg )\n",
    "        # 2. compute corr(x, global_mean)\n",
    "        if ( self.include_global ) :\n",
    "            if ( self.minus_original ) :\n",
    "                mu = K.mean( x, axis=(1,2), keepdims=True )\n",
    "                x_win_avgs.append( mu-x )\n",
    "            else :\n",
    "                mu = K.mean( x, axis=(1,2), keepdims=True ) * K.ones_like(x)\n",
    "                x_win_avgs.append( mu )\n",
    "        if self.output_mode == '4d' :\n",
    "            return K.concatenate( x_win_avgs, axis=-1 )\n",
    "        elif self.output_mode == '5d' :\n",
    "            return K.stack( x_win_avgs, axis=1 )\n",
    "        else :\n",
    "            raise (NotImplementedError, \"ERROR: unknown output_mode={}\".format( self.output_mode ))\n",
    "            \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch_size, num_rows, num_cols, num_filts = input_shape\n",
    "        if self.output_mode == '4d' :\n",
    "            return ( batch_size, num_rows, num_cols, (self.num_woi+int(self.include_global))*num_filts )\n",
    "        else :\n",
    "            return ( batch_size, self.num_woi+int(self.include_global), num_rows, num_cols, num_filts )\n",
    "\n",
    "def create_manTraNet_model( Featex, pool_size_list=[7,15,31], is_dynamic_shape=True, apply_normalization=True ) :\n",
    "    \"\"\"\n",
    "    Create ManTra-Net from a pretrained IMC-Featex model\n",
    "    \"\"\"\n",
    "    img_in = Input(shape=(None,None,3), name='img_in' )\n",
    "    rf = Featex( img_in )\n",
    "    rf = Conv2D( 64, (1,1),\n",
    "                 activation=None, # no need to use tanh if sf is L2normalized\n",
    "                 use_bias=False,\n",
    "                 kernel_constraint = unit_norm( axis=-2 ),\n",
    "                 name='outlierTrans',\n",
    "                 padding = 'same' )(rf)\n",
    "    bf = BatchNormalization( axis=-1, name='bnorm', center=False, scale=False )(rf)\n",
    "    devf5d = NestedWindowAverageFeatExtrator(window_size_list=pool_size_list,\n",
    "                                             output_mode='5d',\n",
    "                                             minus_original=True,\n",
    "                                             name='nestedAvgFeatex' )( bf )\n",
    "    if ( apply_normalization ) :\n",
    "        sigma = GlobalStd2D( name='glbStd' )( bf )\n",
    "        sigma5d = Lambda( lambda t : K.expand_dims( t, axis=1 ), name='expTime')( sigma )\n",
    "        devf5d = Lambda( lambda vs : K.abs(vs[0]/vs[1]), name='divStd' )([devf5d, sigma5d])\n",
    "    # convert back to 4d\n",
    "    devf = ConvLSTM2D( 8, (7,7),\n",
    "                       activation='tanh',\n",
    "                       recurrent_activation='hard_sigmoid',\n",
    "                       padding='same',\n",
    "                       name='cLSTM',\n",
    "                       return_sequences=False )(devf5d)\n",
    "    pred_out = Conv2D(1, (7,7), padding='same', activation='sigmoid', name='pred')( devf )\n",
    "    return Model( inputs=img_in, outputs=pred_out, name='sigNet' )\n",
    "\n",
    "def create_model( IMC_model_idx, freeze_featex, window_size_list ) :\n",
    "    type_idx = IMC_model_idx if IMC_model_idx < 4 else 2\n",
    "    Featex = create_featex_vgg7_base( type_idx )\n",
    "    if freeze_featex :\n",
    "        print (\"INFO: freeze feature extraction part, trainable=False\")\n",
    "        Featex.trainable = False\n",
    "    else :\n",
    "        print (\"INFO: unfreeze feature extraction part, trainable=True\")\n",
    "\n",
    "    if ( len( window_size_list ) == 4 ) :\n",
    "        for ly in Featex.layers[:5] :\n",
    "            ly.trainable = False\n",
    "            print (\"INFO: freeze\", ly.name)\n",
    "    model = create_manTraNet_model( Featex,\n",
    "                                    pool_size_list=window_size_list,\n",
    "                                    is_dynamic_shape=True,\n",
    "                                    apply_normalization=True, )\n",
    "    return model\n",
    "\n",
    "def load_pretrain_model_by_index( pretrain_index, model_dir ) :\n",
    "    if ( pretrain_index == 4 ) :\n",
    "        IMC_model_idx, freeze_featex, window_size_list  = 2, False, [7, 15, 31]\n",
    "    else :\n",
    "        IMC_model_idx, freeze_featex, window_size_list  = pretrain_index, False, [7, 15, 31, 63]\n",
    "    single_gpu_model = create_model( IMC_model_idx, freeze_featex, window_size_list )\n",
    "    weight_file = \"{}/ManTraNet_Ptrain{}.h5\".format( model_dir, pretrain_index )\n",
    "    assert os.path.isfile(weight_file), \"ERROR: fail to locate the pretrained weight file\"\n",
    "    single_gpu_model.load_weights( weight_file )\n",
    "    return single_gpu_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featex_vgg16_base( type=1 ) :\n",
    "    base = 16\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    print(x.shape)\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    # block 3\n",
    "    bname = 'b3'\n",
    "    nb_filters = 4 * base # 96\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c3')( x )\n",
    "    # block 4\n",
    "    bname = 'b4'\n",
    "    nb_filters = 8 * base # 128\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c3')( x )\n",
    "    # block 5/bottle-neck \n",
    "    bname = 'b5'\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    print (\"INFO: use activation in the last CONV={}\".format( activation ))\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ii layer\n",
    "\n",
    "class IlluminationInvariant(Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(IlluminationInvariant, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable alpha for this layer.\n",
    "        self.alpha = self.add_weight(name='alpha', \n",
    "                                      shape=(1,1,1,1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(IlluminationInvariant, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, img):\n",
    "        print(img.dtype, img.shape)\n",
    "        #assert isinstance(img, np.ndarray)\n",
    "        assert(img.shape[3] == 3)\n",
    "        tmp = (0.5 + K.log(img[:, :, 1] / float(255)) -\n",
    "                self.alpha * K.log(img[:, :, 2] / float(255)) -\n",
    "                (1 - self.alpha) * K.log(img[:, :, 0] / float(255)))\n",
    "        return tmp\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], None, None, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dense = Dense(1, activation='sigmoid', activity_regularizer=l1(0.005))\n",
    "def create_featex_vgg7_base1( type=1 ) :\n",
    "    base = 1\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = AveragePooling2D()(x)\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = AveragePooling2D()(x)\n",
    "    # block 3\n",
    "    bname = 'b3'\n",
    "    nb_filters = 4 * base # 96\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = AveragePooling2D()(x)\n",
    "    # block 4/bottle-neck \n",
    "    bname = 'b4'\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    print (\"INFO: use activation in the last CONV={}\".format( activation ))\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n",
    "\n",
    "def create_featex_vgg7_base2( type=1 ) :\n",
    "    base = 4\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = MaxPooling2D()(x)\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = MaxPooling2D()(x)\n",
    "    # block 3\n",
    "    bname = 'b3'\n",
    "    nb_filters = 4 * base # 96\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = MaxPooling2D()(x)\n",
    "    # block 4/bottle-neck \n",
    "    bname = 'b4'\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    print (\"INFO: use activation in the last CONV={}\".format( activation ))\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n",
    "\n",
    "def create_featex_vgg7_base3( type=1 ) :\n",
    "    base = 4\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = AveragePooling2D()(x)\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = AveragePooling2D()(x)\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n",
    "\n",
    "def create_featex_vgg7_base4( type=1 ) :\n",
    "    base = 4\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x1 = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    x2 = IlluminationInvariant()(img_input)\n",
    "    x = Concatenate(axis = -1) ([x1,x2])\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = MaxPooling2D()(x)\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = MaxPooling2D()(x)\n",
    "    # block 3\n",
    "    bname = 'b3'\n",
    "    nb_filters = 4 * base # 96\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = MaxPooling2D()(x)\n",
    "    # block 4/bottle-neck \n",
    "    bname = 'b4'\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    print (\"INFO: use activation in the last CONV={}\".format( activation ))\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n",
    "\n",
    "\n",
    "def create_featex_vgg16_base2( type=1 ) :\n",
    "    base = 2\n",
    "    img_input = Input(shape=(None,None,3), name='image_in')\n",
    "    # block 1\n",
    "    bname = 'b1' # 32\n",
    "    nb_filters = base\n",
    "    x = CombinedConv2D( 32 if type in [0,1] else 16, activation='relu', use_bias=False, padding='same', name=bname+'c1')( img_input )\n",
    "    print(x.shape)\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    # block 2\n",
    "    bname = 'b2'\n",
    "    nb_filters = 2 * base # 64\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    # block 3\n",
    "    bname = 'b3'\n",
    "    nb_filters = 4 * base # 96\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c3')( x )\n",
    "    # block 4\n",
    "    bname = 'b4'\n",
    "    nb_filters = 8 * base # 128\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c3')( x )\n",
    "    # block 5/bottle-neck \n",
    "    bname = 'b5'\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c1')( x )\n",
    "    x = Conv2DSymPadding( nb_filters, (3,3), activation='relu', padding='same',  name=bname+'c2')( x )\n",
    "    activation=None if type >=1 else 'tanh'\n",
    "    print (\"INFO: use activation in the last CONV={}\".format( activation ))\n",
    "    sf = Conv2DSymPadding( nb_filters, (3,3),\n",
    "                           activation=activation,\n",
    "                          name='transform',\n",
    "                          padding='same' )(x)\n",
    "    sf = Lambda( lambda t : K.l2_normalize( t, axis=-1), name='L2')(sf)\n",
    "    return Model( inputs= img_input, outputs=sf, name='Featex')\n",
    "\n",
    "def create_classification_model(Featex) :\n",
    "    \"\"\"\n",
    "    Create a pretrained true/false classification model\n",
    "    \"\"\"\n",
    "    img_in = Input(shape=(224,224,3), name='img_in' )   \n",
    "    rf = Featex( img_in )\n",
    "    # add a cnn layer to condense features\n",
    "    rf = Conv2DSymPadding( 1, (3,3), activation='tanh', padding='same',  name='condense')( rf )\n",
    "    rf = Flatten('channels_first')(rf)\n",
    "    rf = Dropout(rate = 0.2, seed = 0)(rf)\n",
    "    pred_out = dense(rf) \n",
    "    return Model( inputs=img_in, outputs=pred_out, name='VGG7s_Net' )\n",
    "\n",
    "def create_model( IMC_model_idx, freeze_featex, window_size_list ) :\n",
    "    type_idx = IMC_model_idx if IMC_model_idx < 4 else 2\n",
    "    Featex = create_featex_vgg7_base4( type_idx )\n",
    "    if freeze_featex :\n",
    "        print (\"INFO: freeze feature extraction part, trainable=False\")\n",
    "        Featex.trainable = False\n",
    "    else :\n",
    "        print (\"INFO: unfreeze feature extraction part, trainable=True\")\n",
    "\n",
    "    if ( len( window_size_list ) == 4 ) :\n",
    "        for ly in Featex.layers[:5] :\n",
    "            ly.trainable = False\n",
    "            print (\"INFO: freeze\", ly.name)\n",
    "    model = create_classification_model(Featex)\n",
    "    return model\n",
    "\n",
    "def create_classification_modelS(Featex) :\n",
    "    \"\"\"\n",
    "    Create a pretrained true/false classification model\n",
    "    \"\"\"\n",
    "    img_in = Input(shape=(56,56,3), name='img_in' )   \n",
    "    rf = Featex( img_in )\n",
    "    # add a cnn layer to condense features\n",
    "    rf = Conv2DSymPadding( 1, (3,3), activation='tanh', padding='same',  name='condense')( rf )\n",
    "    rf = Flatten('channels_first')(rf)\n",
    "    rf = Dropout(rate = 0.2, seed = 0)(rf)\n",
    "    pred_out = dense(rf) \n",
    "    return Model( inputs=img_in, outputs=pred_out, name='VGG7s_Net' )\n",
    "\n",
    "def create_modelS( IMC_model_idx, freeze_featex, window_size_list ) :\n",
    "    type_idx = IMC_model_idx if IMC_model_idx < 4 else 2\n",
    "    Featex = create_featex_vgg7_base2( type_idx )\n",
    "    if freeze_featex :\n",
    "        print (\"INFO: freeze feature extraction part, trainable=False\")\n",
    "        Featex.trainable = False\n",
    "    else :\n",
    "        print (\"INFO: unfreeze feature extraction part, trainable=True\")\n",
    "\n",
    "    if ( len( window_size_list ) == 4 ) :\n",
    "        for ly in Featex.layers[:5] :\n",
    "            ly.trainable = False\n",
    "            print (\"INFO: freeze\", ly.name)\n",
    "    model = create_classification_modelS(Featex)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X,Y):\n",
    "    m, dx, dy, chn = X.shape\n",
    "    ddx = int(dx/2)\n",
    "    ddy = int(dy/2)\n",
    "    m = int(m)\n",
    "    X_split = np.zeros((4*m, ddx, ddy,3))\n",
    "    Y_split = np.zeros((4*m, ddx, ddy,1))\n",
    "    for i in np.arange(0,m):\n",
    "        X_split[i,0:ddx,0:ddy,:] = X[i,0:ddx,0:ddy,:]\n",
    "        Y_split[i,0:ddx,0:ddy,:] = Y[i,0:ddx,0:ddy,:]\n",
    "        X_split[i+m,0:ddx,0:ddy,:] = X[i,ddx:,0:ddy,:]\n",
    "        Y_split[i+m,0:ddx,0:ddy,:] = Y[i,ddx:,0:ddy,:]\n",
    "        X_split[i+m*2,0:ddx,0:ddy,:] = X[i,0:ddx,ddy:,:]\n",
    "        Y_split[i+m*2,0:ddx,0:ddy,:] = Y[i,0:ddx,ddy:,:]\n",
    "        X_split[i+m*3,0:ddx,0:ddy,:] = X[i,ddx:,ddy:,:]\n",
    "        Y_split[i+m*3,0:ddx,0:ddy,:] = Y[i,ddx:,ddy:,:]\n",
    "    return X_split, Y_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 224x224 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train_1.npy')\n",
    "Y_train = np.load('X_train_1.npy')\n",
    "y = np.zeros((Y_train.shape[0],1))\n",
    "for i in np.arange(0,Y_train.shape[0]):\n",
    "    y[i] = np.sum(Y_train[i])/(224*224)\n",
    "y = y > 0.0\n",
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification Model Tests\n",
    "os.chdir('/home/ubuntu/')\n",
    "cl_model1 = create_model(2, False, [7, 15, 31])\n",
    "#weight_file = \"output/vgg_small_endtoend-20.hdf5\"\n",
    "#single_gpu_model.load_weights( weight_file )\n",
    "cl_model1.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "cl_model1.summary()\n",
    "filepath = \"output/small_classification_vgg7base2L-{epoch:02d}.hdf5\"\n",
    "#filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "cl_model1.fit(X_train, y, epochs=20, batch_size=20, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('X_test_1.npy')\n",
    "Y_test = np.load('Y_test_1.npy')\n",
    "y_test = np.zeros((Y_test.shape[0],1))\n",
    "for i in np.arange(0,Y_test.shape[0]):\n",
    "    y_test[i] = np.sum(Y_test[i])/(56*56)\n",
    "y_test = y_test > 0.0\n",
    "print(np.sum(y_test))\n",
    "y_pred = cl_model1.predict(X_test)\n",
    "ypreds = cl_model1.evaluate(X_test,y_test)\n",
    "print(ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "Y_pred = y_pred > 0.5\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, Y_pred)\n",
    "metrics.auc(fpr, tpr)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 56x56 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6297\n"
     ]
    }
   ],
   "source": [
    "# get training dataset for classification\n",
    "X_train = np.load('X_train_2.npy')\n",
    "Y_train = np.load('Y_train_2.npy')\n",
    "\n",
    "y = np.zeros((Y_train.shape[0],1))\n",
    "for i in np.arange(0,Y_train.shape[0]):\n",
    "    y[i] = np.sum(Y_train[i])/(224*224)\n",
    "y = y > 0.0\n",
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Train 1\n",
      "# of images is 8000\n",
      "# of fake images is 0.310875\n",
      "ratio of fake pixes is 0.09096394376109815\n",
      "-----------------\n",
      "dev 1\n",
      "# of images is 1000\n",
      "# of fake images is 0.292\n",
      "ratio of fake pixes is 0.08418543479891956\n",
      "-----------------\n",
      "Test 1\n",
      "# of images is 1000\n",
      "# of fake images is 0.302\n",
      "ratio of fake pixes is 0.08016505211459583\n",
      "-----------------\n",
      "Train 2\n",
      "# of images is 6400\n",
      "# of fake images is 0.98390625\n",
      "ratio of fake pixes is 0.16130094705118395\n",
      "-----------------\n",
      "dev 2\n",
      "# of images is 800\n",
      "# of fake images is 0.97125\n",
      "ratio of fake pixes is 0.16854748647505877\n",
      "-----------------\n",
      "Test 2\n",
      "# of images is 800\n",
      "# of fake images is 0.97875\n",
      "ratio of fake pixes is 0.1679811650246035\n"
     ]
    }
   ],
   "source": [
    "Y = np.load('Y_train_1.npy')\n",
    "print('-----------------')\n",
    "print('Train 1')\n",
    "print('# of images is {}'.format(Y.shape[0]))\n",
    "count = 0\n",
    "for i in np.arange(0,Y.shape[0]):\n",
    "    if np.sum(Y[i] > 0):\n",
    "        count += 1\n",
    "print('# of fake images is {}'.format(count/Y.shape[0]))\n",
    "print('ratio of fake pixes is {}'.format(np.sum(Y)/Y.shape[0]/224/224))\n",
    "      \n",
    "Y = np.load('Y_dev_1.npy')\n",
    "print('-----------------')\n",
    "print('dev 1')\n",
    "print('# of images is {}'.format(Y.shape[0]))\n",
    "count = 0\n",
    "for i in np.arange(0,Y.shape[0]):\n",
    "    if np.sum(Y[i] > 0):\n",
    "        count += 1\n",
    "print('# of fake images is {}'.format(count/Y.shape[0]))\n",
    "print('ratio of fake pixes is {}'.format(np.sum(Y)/Y.shape[0]/224/224))\n",
    "\n",
    "Y = np.load('Y_test_1.npy')\n",
    "print('-----------------')\n",
    "print('Test 1')\n",
    "print('# of images is {}'.format(Y.shape[0]))\n",
    "count = 0\n",
    "for i in np.arange(0,Y.shape[0]):\n",
    "    if np.sum(Y[i] > 0):\n",
    "        count += 1\n",
    "print('# of fake images is {}'.format(count/Y.shape[0]))\n",
    "print('ratio of fake pixes is {}'.format(np.sum(Y)/Y.shape[0]/224/224))\n",
    "      \n",
    "Y = np.load('Y_train_2.npy')\n",
    "print('-----------------')\n",
    "print('Train 2')\n",
    "print('# of images is {}'.format(Y.shape[0]))\n",
    "count = 0\n",
    "for i in np.arange(0,Y.shape[0]):\n",
    "    if np.sum(Y[i] > 0):\n",
    "        count += 1\n",
    "print('# of fake images is {}'.format(count/Y.shape[0]))\n",
    "print('ratio of fake pixes is {}'.format(np.sum(Y)/Y.shape[0]/224/224))\n",
    "      \n",
    "Y = np.load('Y_dev_2.npy')\n",
    "print('-----------------')\n",
    "print('dev 2')\n",
    "print('# of images is {}'.format(Y.shape[0]))\n",
    "count = 0\n",
    "for i in np.arange(0,Y.shape[0]):\n",
    "    if np.sum(Y[i] > 0):\n",
    "        count += 1\n",
    "print('# of fake images is {}'.format(count/Y.shape[0]))\n",
    "print('ratio of fake pixes is {}'.format(np.sum(Y)/Y.shape[0]/224/224))\n",
    "\n",
    "Y = np.load('Y_test_2.npy')\n",
    "print('-----------------')\n",
    "print('Test 2')\n",
    "print('# of images is {}'.format(Y.shape[0]))\n",
    "count = 0\n",
    "for i in np.arange(0,Y.shape[0]):\n",
    "    if np.sum(Y[i] > 0):\n",
    "        count += 1\n",
    "print('# of fake images is {}'.format(count/Y.shape[0]))\n",
    "print('ratio of fake pixes is {}'.format(np.sum(Y)/Y.shape[0]/224/224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('X_test_1.npy')\n",
    "Y_test = np.load('Y_test_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35713\n"
     ]
    }
   ],
   "source": [
    "# split the data into smaller patches for training\n",
    "X1, Y1 = split_dataset(X_train, Y_train)\n",
    "X1, Y1 = split_dataset(X1, Y1)\n",
    "y = np.zeros((Y1.shape[0],1))\n",
    "for i in np.arange(0,Y1.shape[0]):\n",
    "    y[i] = np.sum(Y1[i])/(224*224)\n",
    "y = y > 0.0\n",
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "INFO: use activation in the last CONV=None\n",
      "INFO: unfreeze feature extraction part, trainable=True\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_in (InputLayer)          (None, 56, 56, 3)         0         \n",
      "_________________________________________________________________\n",
      "Featex (Model)               multiple                  9529      \n",
      "_________________________________________________________________\n",
      "condense (Conv2DSymPadding)  (None, 7, 7, 1)           145       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 50        \n",
      "=================================================================\n",
      "Total params: 9,724\n",
      "Trainable params: 9,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# classification Model Tests\n",
    "os.chdir('/home/ubuntu/')\n",
    "cl_model = create_modelS(2, False, [7, 15, 31])\n",
    "#weight_file = \"output/vgg_small_endtoend-20.hdf5\"\n",
    "#single_gpu_model.load_weights( weight_file )\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "cl_model.compile(optimizer = \"SGD\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "cl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102400/102400 [==============================] - 176s 2ms/step - loss: 0.6629 - acc: 0.6657\n",
      "Epoch 2/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.6390 - acc: 0.6903\n",
      "Epoch 3/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.6025 - acc: 0.7220\n",
      "Epoch 4/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.5524 - acc: 0.7608\n",
      "Epoch 5/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.5263 - acc: 0.7764\n",
      "Epoch 6/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.5142 - acc: 0.7852\n",
      "Epoch 7/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.5075 - acc: 0.7882\n",
      "Epoch 8/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.5024 - acc: 0.7919\n",
      "Epoch 9/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.5097 - acc: 0.7859\n",
      "Epoch 10/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.4999 - acc: 0.7923\n",
      "Epoch 11/20\n",
      "102400/102400 [==============================] - 173s 2ms/step - loss: 0.4904 - acc: 0.7991\n",
      "Epoch 12/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.4847 - acc: 0.8019\n",
      "Epoch 13/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.4791 - acc: 0.8043\n",
      "Epoch 14/20\n",
      "102400/102400 [==============================] - 173s 2ms/step - loss: 0.4713 - acc: 0.8091\n",
      "Epoch 15/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.4773 - acc: 0.8058\n",
      "Epoch 16/20\n",
      "102400/102400 [==============================] - 173s 2ms/step - loss: 0.4652 - acc: 0.8140\n",
      "Epoch 17/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.4580 - acc: 0.8172\n",
      "Epoch 18/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.4618 - acc: 0.8157\n",
      "Epoch 19/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.4547 - acc: 0.8208\n",
      "Epoch 20/20\n",
      "102400/102400 [==============================] - 172s 2ms/step - loss: 0.4603 - acc: 0.8174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbe93fd438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"output/small_classification_vgg7base2-001-{epoch:02d}.hdf5\"\n",
    "#filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "cl_model.fit(X1, y, epochs=20, batch_size=20, callbacks = [checkpoint])\n",
    "# lr = 0.001 sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: use activation in the last CONV=None\n",
      "INFO: unfreeze feature extraction part, trainable=True\n"
     ]
    }
   ],
   "source": [
    "# load final result\n",
    "clf_model = create_modelS(2, False, [7, 15, 31])\n",
    "weight_file = \"output/small_classification_vgg7base2-001-20.hdf5\"\n",
    "clf_model.load_weights( weight_file )\n",
    "clf_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2101\n",
      "102400/102400 [==============================] - 50s 489us/step\n",
      "[0.45792015673127023, 0.827490234375]\n"
     ]
    }
   ],
   "source": [
    "# load test set\n",
    "X_test = np.load('X_test_1.npy')\n",
    "Y_test = np.load('Y_test_1.npy')\n",
    "X_test, Y_test = split_dataset(X_test, Y_test)\n",
    "X_test, Y_test = split_dataset(X_test, Y_test)\n",
    "y_test = np.zeros((Y_test.shape[0],1))\n",
    "for i in np.arange(0,Y_test.shape[0]):\n",
    "    y_test[i] = np.sum(Y_test[i])/(56*56)\n",
    "y_test = y_test > 0.0\n",
    "print(np.sum(y_test))\n",
    "ypreds = clf_model.evaluate(X1, y)\n",
    "print(ypreds)\n",
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test AUC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "AUC = metrics.auc(fpr, tpr)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf_model.evaluate(X_test, y_test)\n",
    "print(y_test.dtype, y_test.shape)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)\n",
    "print(y_pred.shape, y_pred.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test AUC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "AUC = metrics.auc(fpr, tpr)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export and save data\n",
    "import scipy.io as sio\n",
    "sio.savemat('dean0_classification',{'tpr':tpr, 'fpr':fpr, 'AUC': AUC, 'TestLoss':preds[0], 'TestACC':preds[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data1: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training dataset for classification\n",
    "X_train = np.load('X_train_1.npy')\n",
    "Y_train = np.load('Y_train_1.npy')\n",
    "\n",
    "# split the data into smaller patches for training\n",
    "X1, Y1 = split_dataset(X_train, Y_train)\n",
    "X1, Y1 = split_dataset(X1, Y1)\n",
    "y = np.zeros((Y1.shape[0],1))\n",
    "for i in np.arange(0,Y1.shape[0]):\n",
    "    y[i] = np.sum(Y1[i])/(224*224)\n",
    "y = y > 0.0\n",
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification Model Tests\n",
    "os.chdir('/home/ubuntu/')\n",
    "cl_model1 = create_modelS(2, False, [7, 15, 31])\n",
    "#weight_file = \"output/vgg_small_endtoend-20.hdf5\"\n",
    "#single_gpu_model.load_weights( weight_file )\n",
    "cl_model1.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "cl_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"output/small_classification_vgg7base2_data1-{epoch:02d}.hdf5\"\n",
    "#filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "cl_model1.fit(X1, y, epochs=20, batch_size=20, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "X_test = np.load('X_test_1.npy')\n",
    "Y_test = np.load('Y_test_1.npy')\n",
    "X_test, Y_test = split_dataset(X_test, Y_test)\n",
    "X_test, Y_test = split_dataset(X_test, Y_test)\n",
    "y_test = np.zeros((Y_test.shape[0],1))\n",
    "for i in np.arange(0,Y_test.shape[0]):\n",
    "    y_test[i] = np.sum(Y_test[i])/(56*56)\n",
    "y_test = y_test > 0.0\n",
    "print(np.sum(y_test))\n",
    "ypreds = clf_model.evaluate(X1, y)\n",
    "print(ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)\n",
    "print(y_pred.shape, y_pred.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test AUC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "AUC = metrics.auc(fpr, tpr)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LADN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/')\n",
    "#manTraNet = load_pretrain_model_by_index(1, manTraNet_modelDir)\n",
    "single_gpu_model = create_model(2, False, [7, 15, 31])\n",
    "weight_file = \"output/vgg_small_endtoend-20.hdf5\"\n",
    "single_gpu_model.load_weights( weight_file )\n",
    "single_gpu_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "single_gpu_model.summary()\n",
    "y_pred=single_gpu_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test.reshape((Y_test.shape[0] * Y_test.shape[1] * Y_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "Y_pred = y_pred > 0.5\n",
    "Y_pred = Y_pred.reshape((Y_pred.shape[0] * Y_pred.shape[1] * Y_pred.shape[2]))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_pred = y_pred > 0.55\n",
    "Y_pred = y_pred\n",
    "Y_test1 = Y_test1 >= .9\n",
    "print(Y_test.dtype)\n",
    "print(Y_pred.dtype)\n",
    "Y_pred = Y_pred.reshape((Y_pred.shape[0] * Y_pred.shape[1] * Y_pred.shape[2]))\n",
    "print(Y_test1.dtype)\n",
    "print(Y_pred.dtype)\n",
    "#cm=confusion_matrix(Y_test1,Y_pred)\n",
    "#print(cm)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test1, Y_pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark pretrained_model\n",
    "import modelCore\n",
    "bm = modelCore.load_pretrain_model_by_index(4,manTraNet_modelDir)\n",
    "y_pred=bm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = y_pred\n",
    "Y_test1 = Y_test1 >= .9\n",
    "print(Y_test.dtype)\n",
    "print(Y_pred.dtype)\n",
    "Y_pred = Y_pred.reshape((Y_pred.shape[0] * Y_pred.shape[1] * Y_pred.shape[2]))\n",
    "print(Y_test1.dtype)\n",
    "print(Y_pred.dtype)\n",
    "#cm=confusion_matrix(Y_test1,Y_pred)\n",
    "#print(cm)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test1, Y_pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y = np.load('Y_test.npy')\n",
    "X = np.load('X_test.npy')\n",
    "\n",
    "plt.imshow(Y[108,:,:,0])\n",
    "plt.colorbar()\n",
    "plt.clim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for idx in np.arange(0,1000):\n",
    "    if np.sum(Y[idx,:,:,0]) < 224*50:\n",
    "        if np.sum(Y[idx,:,:,0]) > 1000:\n",
    "            lst.append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((X[108,:,:,:]+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"output/small_classification-{epoch:02d}.hdf5\"\n",
    "#filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "cl_model.fit(X, y, epochs=10, batch_size=18, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
